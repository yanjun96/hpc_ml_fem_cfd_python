{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c49f2a-168e-4e91-9071-815bf55c98ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29b1577-2cf8-4ebe-b295-85c65bfb07c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras_flops import get_flops\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "def load_time_series_data():\n",
    "    \"\"\"Load data where each test has one time series of temperatures\"\"\"\n",
    "    summary_df = pd.read_csv('all_time.csv')\n",
    "    test_data = []\n",
    "    \n",
    "    for i in range(1, 26):\n",
    "        try:\n",
    "            filename = f'csv_ave/{i}.csv'\n",
    "            df = pd.read_csv(filename, header=1)\n",
    "            test_params = summary_df.iloc[i-1][['Fb_set\\n[kN]', 'v_set\\n[km/h]', 'μ_m', 't2\\n[s]']].values\n",
    "            temperature_series = df.iloc[:, 3].values\n",
    "            \n",
    "            test_data.append({\n",
    "                'Fb_set': test_params[0],\n",
    "                'v_set': test_params[1],\n",
    "                'μ_m': test_params[2],\n",
    "                't2': test_params[3],\n",
    "                'temperature_series': temperature_series\n",
    "            })\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "def resample_series(temp_series, original_length, target_length=1500):\n",
    "    \"\"\"Resample time series to target length using linear interpolation\"\"\"\n",
    "    original_time = np.linspace(0, 1, original_length)\n",
    "    target_time = np.linspace(0, 1, target_length)\n",
    "    return np.interp(target_time, original_time, temp_series)\n",
    "\n",
    "# Load and preprocess data\n",
    "test_data = load_time_series_data()\n",
    "TARGET_LENGTH = 4000  # Fixed length for all series\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for test in test_data:\n",
    "    # Input features\n",
    "    X.append([test['Fb_set'], test['v_set'], test['μ_m'], test['t2']])\n",
    "    \n",
    "    # Resample temperature series\n",
    "    original_length = len(test['temperature_series'])\n",
    "    resampled = resample_series(\n",
    "        test['temperature_series'],\n",
    "        original_length,\n",
    "        TARGET_LENGTH\n",
    "    )\n",
    "    y.append(resampled)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a65f9c4-e29d-4062-925a-37601c1969f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 4)\n",
      "(11, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf988337-3f92-4d25-ad31-e8dc9a870fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4000, 64)          33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4000, 1)           65        \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8 samples, validate on 1 samples\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 17s 2s/sample - loss: 0.9473 - mean_absolute_error: 0.8298 - val_loss: 0.3121 - val_mean_absolute_error: 0.3649\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1995 - mean_absolute_error: 0.3243 - val_loss: 0.6487 - val_mean_absolute_error: 0.6850\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.2846 - mean_absolute_error: 0.3835 - val_loss: 0.3267 - val_mean_absolute_error: 0.3815\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1648 - mean_absolute_error: 0.2924 - val_loss: 0.1916 - val_mean_absolute_error: 0.3169\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.2027 - mean_absolute_error: 0.3583 - val_loss: 0.2129 - val_mean_absolute_error: 0.3677\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.2029 - mean_absolute_error: 0.3496 - val_loss: 0.1863 - val_mean_absolute_error: 0.2976\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1784 - mean_absolute_error: 0.3235 - val_loss: 0.1967 - val_mean_absolute_error: 0.1971\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1255 - mean_absolute_error: 0.2209 - val_loss: 0.2595 - val_mean_absolute_error: 0.2794\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1701 - mean_absolute_error: 0.2728 - val_loss: 0.3411 - val_mean_absolute_error: 0.3999\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1693 - mean_absolute_error: 0.2687 - val_loss: 0.3334 - val_mean_absolute_error: 0.3902\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1931 - mean_absolute_error: 0.2975 - val_loss: 0.2601 - val_mean_absolute_error: 0.2806\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1513 - mean_absolute_error: 0.2593 - val_loss: 0.2033 - val_mean_absolute_error: 0.1862\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1242 - mean_absolute_error: 0.1973 - val_loss: 0.1819 - val_mean_absolute_error: 0.2556\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1544 - mean_absolute_error: 0.2765 - val_loss: 0.1892 - val_mean_absolute_error: 0.3108\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1284 - mean_absolute_error: 0.2352 - val_loss: 0.2044 - val_mean_absolute_error: 0.3514\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1453 - mean_absolute_error: 0.2513 - val_loss: 0.2030 - val_mean_absolute_error: 0.3484\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1348 - mean_absolute_error: 0.2300 - val_loss: 0.1932 - val_mean_absolute_error: 0.3237\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1245 - mean_absolute_error: 0.2052 - val_loss: 0.1836 - val_mean_absolute_error: 0.2848\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1319 - mean_absolute_error: 0.2139 - val_loss: 0.1832 - val_mean_absolute_error: 0.2395\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1376 - mean_absolute_error: 0.2143 - val_loss: 0.1935 - val_mean_absolute_error: 0.2034\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1220 - mean_absolute_error: 0.2064 - val_loss: 0.2133 - val_mean_absolute_error: 0.1982\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1260 - mean_absolute_error: 0.2131 - val_loss: 0.2296 - val_mean_absolute_error: 0.2236\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1335 - mean_absolute_error: 0.1993 - val_loss: 0.2403 - val_mean_absolute_error: 0.2429\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1322 - mean_absolute_error: 0.2173 - val_loss: 0.2272 - val_mean_absolute_error: 0.2195\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1377 - mean_absolute_error: 0.2412 - val_loss: 0.2026 - val_mean_absolute_error: 0.1869\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1280 - mean_absolute_error: 0.1996 - val_loss: 0.1873 - val_mean_absolute_error: 0.2202\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 14s 2s/sample - loss: 0.1261 - mean_absolute_error: 0.2108 - val_loss: 0.1819 - val_mean_absolute_error: 0.2528\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 14s 2s/sample - loss: 0.1359 - mean_absolute_error: 0.2225 - val_loss: 0.1829 - val_mean_absolute_error: 0.2801\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 14s 2s/sample - loss: 0.1366 - mean_absolute_error: 0.2430 - val_loss: 0.1859 - val_mean_absolute_error: 0.2978\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1317 - mean_absolute_error: 0.2184 - val_loss: 0.1877 - val_mean_absolute_error: 0.3053\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1483 - mean_absolute_error: 0.2611 - val_loss: 0.1856 - val_mean_absolute_error: 0.2963\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1407 - mean_absolute_error: 0.2423 - val_loss: 0.1829 - val_mean_absolute_error: 0.2798\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1328 - mean_absolute_error: 0.2243 - val_loss: 0.1817 - val_mean_absolute_error: 0.2595\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 14s 2s/sample - loss: 0.1272 - mean_absolute_error: 0.2061 - val_loss: 0.1844 - val_mean_absolute_error: 0.2323\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1302 - mean_absolute_error: 0.2062 - val_loss: 0.1909 - val_mean_absolute_error: 0.2097\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1262 - mean_absolute_error: 0.2125 - val_loss: 0.1983 - val_mean_absolute_error: 0.1940\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 14s 2s/sample - loss: 0.1192 - mean_absolute_error: 0.1888 - val_loss: 0.2071 - val_mean_absolute_error: 0.1899\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 15s 2s/sample - loss: 0.1256 - mean_absolute_error: 0.2166 - val_loss: 0.2137 - val_mean_absolute_error: 0.1987\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1273 - mean_absolute_error: 0.2200 - val_loss: 0.2130 - val_mean_absolute_error: 0.1978\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1506 - mean_absolute_error: 0.2523 - val_loss: 0.2086 - val_mean_absolute_error: 0.1918\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1384 - mean_absolute_error: 0.2349 - val_loss: 0.2048 - val_mean_absolute_error: 0.1872\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1201 - mean_absolute_error: 0.1959 - val_loss: 0.2012 - val_mean_absolute_error: 0.1889\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1244 - mean_absolute_error: 0.1939 - val_loss: 0.1946 - val_mean_absolute_error: 0.2010\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1225 - mean_absolute_error: 0.1904 - val_loss: 0.1893 - val_mean_absolute_error: 0.2142\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1375 - mean_absolute_error: 0.2398 - val_loss: 0.1858 - val_mean_absolute_error: 0.2258\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 12s 2s/sample - loss: 0.1271 - mean_absolute_error: 0.1921 - val_loss: 0.1837 - val_mean_absolute_error: 0.2360\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1266 - mean_absolute_error: 0.2081 - val_loss: 0.1830 - val_mean_absolute_error: 0.2410\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1251 - mean_absolute_error: 0.1943 - val_loss: 0.1825 - val_mean_absolute_error: 0.2449\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1293 - mean_absolute_error: 0.2097 - val_loss: 0.1831 - val_mean_absolute_error: 0.2396\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 13s 2s/sample - loss: 0.1203 - mean_absolute_error: 0.1969 - val_loss: 0.1855 - val_mean_absolute_error: 0.2269\n",
      "Test MSE: 3.8043, Test MAE: 0.6414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler_y.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    X, y, test_size=0.1, random_state=42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1,random_state=42)\n",
    "\n",
    "# Normalization\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "y_train = np.expand_dims(y_train, axis=-1)  # Shape [batch_size, timesteps, 1]\n",
    "y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "# 2. Model Definition\n",
    "def build_model():\n",
    "    inputs = keras.Input(shape=(4,))  # 4 input features\n",
    "    \n",
    "    # Feature extraction\n",
    "    params = layers.Dense(64, activation='relu')(inputs)\n",
    "    params = layers.Dropout(0.2)(params)\n",
    "    \n",
    "    # Repeat for time steps\n",
    "    repeated = layers.RepeatVector(TARGET_LENGTH)(params)\n",
    "    \n",
    "    # Temporal processing\n",
    "    lstm_out = layers.LSTM(64, return_sequences=True)(repeated)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(1))(lstm_out)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# 3. Training Configuration\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=100, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# 4. Training\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1)\n",
    "\n",
    "# 5. Evaluation\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test MSE: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# 6. Save artifacts\n",
    "model.save('brake_temp_model.keras')\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd41323-87d0-40ba-888a-de15aa022833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Prediction and Visualization\n",
    "def predict_temperature_series(Fb_set, v_set, mu_m, t2):\n",
    "    \"\"\"Predict resampled temperature series\"\"\"\n",
    "    model = keras.models.load_model('brake_temp_model.keras')\n",
    "    scaler_X = joblib.load('scaler_X.pkl')\n",
    "    scaler_y = joblib.load('scaler_y.pkl')\n",
    "    \n",
    "    input_data = scaler_X.transform(np.array([[Fb_set, v_set, mu_m, t2]]))\n",
    "    prediction = model.predict(input_data)\n",
    "    return scaler_y.inverse_transform(prediction.reshape(1, -1))[0]\n",
    "\n",
    "def plot_comparison(Fb_set, v_set, mu_m, t2):\n",
    "    \"\"\"Compare actual vs predicted with correct time scaling\"\"\"\n",
    "    # Get prediction\n",
    "    pred = predict_temperature_series(Fb_set, v_set, mu_m, t2)\n",
    "    \n",
    "    # Find matching test data\n",
    "    actual_series = None\n",
    "    for test in test_data:\n",
    "        if (np.isclose(test['Fb_set'], Fb_set) and\n",
    "            np.isclose(test['v_set'], v_set) and\n",
    "            np.isclose(test['μ_m'], mu_m) and\n",
    "            np.isclose(test['t2'], t2)):\n",
    "            actual_series = test['temperature_series']\n",
    "            break\n",
    "    \n",
    "    # Create time axes\n",
    "    pred_time = np.linspace(0, t2, TARGET_LENGTH)\n",
    "    if actual_series is not None:\n",
    "        actual_time = np.linspace(0, t2, len(actual_series))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if actual_series is not None:\n",
    "        plt.plot(actual_time, actual_series, 'b-', label='Actual', linewidth=2)\n",
    "    plt.plot(pred_time, pred, 'r--', label='Predicted', linewidth=2)\n",
    "    \n",
    "    plt.title(f'Temperature Profile\\n(Fb={Fb_set} kN, v={v_set} km/h, μ={mu_m}, t2={t2}s)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Temperature (°C)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "#if len(test_data) > 0:\n",
    "#    sample = test_data[0]\n",
    "#    plot_comparison(sample['Fb_set'],sample['v_set'],sample['μ_m'],sample['t2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63371c90-09fb-4152-9d37-bd8aa01de186",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15820/515318967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1. Get predictions and experimental data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_temperature_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.376\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mT_expe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ave'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15820/3916117608.py\u001b[0m in \u001b[0;36mpredict_temperature_series\u001b[0;34m(Fb_set, v_set, mu_m, t2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_temperature_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFb_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Predict resampled temperature series\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'brake_temp_model.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mscaler_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler_X.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscaler_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'scaler_y.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    141\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    142\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m    162\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Get predictions and experimental data\n",
    "pred = predict_temperature_series(23, 160, 0.376, 49.1)\n",
    "pd1 = pd.read_csv('4.csv')\n",
    "T_expe = np.array(pd1['ave'])\n",
    "\n",
    "# 2. Resample experimental data to match prediction length\n",
    "def resample_to_target(original_series, original_length, target_length):\n",
    "    \"\"\"Resample using linear interpolation\"\"\"\n",
    "    original_time = np.linspace(0, 1, original_length)\n",
    "    target_time = np.linspace(0, 1, target_length)\n",
    "    return np.interp(target_time, original_time, original_series)\n",
    "\n",
    "T_expe_resampled = resample_to_target(\n",
    "    T_expe, \n",
    "    len(T_expe), \n",
    "    len(pred)\n",
    ")\n",
    "\n",
    "# 3. Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(pred, T_expe_resampled))\n",
    "print(f\"RMSE: {rmse:.2f} °C\")\n",
    "\n",
    "# 4. Add to plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "time_expe = np.arange(len(T_expe)) * (49.1/len(T_expe))\n",
    "plt.plot(time_expe, T_expe, label='Experimental',marker='d',markevery=1000)\n",
    "\n",
    "time_pred = np.arange(len(pred)) * (49.1/len(pred))\n",
    "plt.plot(time_pred, pred, label=f'Predicted (RMSE={rmse:.1f}°C)',marker='o', markevery=100)\n",
    "\n",
    "glb = 14\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "#plt.title('Fb=23 kN, v=160 km/h, μ=0.376, braking time=49 s')\n",
    "plt.xlabel('Time /s', fontsize=glb)\n",
    "plt.ylabel('Temperature /°C', fontsize=glb)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('machine_12.0.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509ac61-b2b1-40ae-bddb-45d4ac58d852",
   "metadata": {},
   "source": [
    "2025-6-19, until now, the best RMSE is 13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c5088-5745-4439-abfd-cd397d4e42af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889ff4a-b1dd-4b5b-b772-e26b8182f3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF 1.15)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
